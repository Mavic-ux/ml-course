{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "13pL--6rycN3"
   },
   "source": [
    "## Homework02: Three headed network in PyTorch\n",
    "\n",
    "This notebook accompanies the [week02](https://github.com/girafe-ai/natural-language-processing/tree/master/week02_cnn_for_texts) practice session. Refer to that notebook for more comments.\n",
    "\n",
    "All the preprocessing is the same as in the classwork. *Including the data leakage in the train test split (it's still for bonus points).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P8zS7m-gycN5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have already downloaded the data on the Seminar, simply run through the next cells. Otherwise uncomment the next cell (and comment the another one ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    17    0    17    0     0     45      0 --:--:-- --:--:-- --:--:--    45\n",
      "100   869  100   869    0     0   1326      0 --:--:-- --:--:-- --:--:--  1326\n",
      "\n",
      "gzip: stdin: not in gzip format\n",
      "tar: Child returned status 1\n",
      "tar: Error is not recoverable: exiting now\n",
      "--2023-05-14 23:37:07--  https://raw.githubusercontent.com/girafe-ai/natural-language-processing/22f_msai/homeworks/assignment02_three_headed_network/network.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1469 (1,4K) [text/plain]\n",
      "Saving to: ‘network.py.3’\n",
      "\n",
      "network.py.3        100%[===================>]   1,43K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-05-14 23:37:08 (17,2 MB/s) - ‘network.py.3’ saved [1469/1469]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# uncomment and run this cell, if you don't have data locally yet.\n",
    "\n",
    "!curl -L \"https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=1\" -o Train_rev1.csv.tar.gz\n",
    "!tar -xvzf ./Train_rev1.csv.tar.gz\n",
    "\n",
    "data = pd.read_csv(\"./Train_rev1.csv\", index_col=None)\n",
    "\n",
    "!wget https://raw.githubusercontent.com/girafe-ai/natural-language-processing/22f_msai/homeworks/assignment02_three_headed_network/network.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "vwN72gd4ycOA",
    "outputId": "7b9e8549-3128-4041-c4be-33fb6f326c78"
   },
   "outputs": [],
   "source": [
    "# run this cell if you have downloaded the dataset on the seminar\n",
    "data = pd.read_csv(\"Train_rev1.csv\", index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "UuuKIKfrycOH",
    "outputId": "e5de0f94-a4f6-4b51-db80-9d11ddc1db31"
   },
   "outputs": [],
   "source": [
    "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
    "text_columns = [\"Title\", \"FullDescription\"]\n",
    "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
    "target_column = \"Log1pSalary\"\n",
    "\n",
    "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
    "\n",
    "data.sample(3)\n",
    "\n",
    "\n",
    "data_for_autotest = data[-5000:]\n",
    "data = data[:-5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RUWkpd7PycOQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized:\n",
      "2         mathematical modeller / simulation analyst / o...\n",
      "100002    a successful and high achieving specialist sch...\n",
      "200002    web designer html , css , javascript , photosh...\n",
      "Name: FullDescription, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239768it [00:09, 25849.57it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "# see task above\n",
    "def normalize(text):\n",
    "    text = str(text).lower()\n",
    "    return ' '.join(tokenizer.tokenize(text))\n",
    "    \n",
    "data[text_columns] = data[text_columns].applymap(normalize)\n",
    "\n",
    "print(\"Tokenized:\")\n",
    "print(data[\"FullDescription\"][2::100000])\n",
    "assert data[\"FullDescription\"][2][:50] == 'mathematical modeller / simulation analyst / opera'\n",
    "assert data[\"Title\"][54321] == 'international digital account manager ( german )'\n",
    "\n",
    "# Count how many times does each token occur in both \"Title\" and \"FullDescription\" in total\n",
    "# build a dictionary { token -> it's count }\n",
    "from collections import Counter\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "token_counts = Counter()# <YOUR CODE HERE>\n",
    "for _, row in tqdm(data[text_columns].iterrows()):\n",
    "    for string in row:\n",
    "        token_counts.update(string.split())\n",
    "\n",
    "# hint: you may or may not want to use collections.Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2598827"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_counts.most_common(1)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "id": "GiOWbc15ycOb",
    "outputId": "1e807140-5513-4af0-d9a9-9f029059a553"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique tokens : 201127\n",
      "('and', 2598827)\n",
      "('.', 2471477)\n",
      "(',', 2266256)\n",
      "('the', 2036428)\n",
      "('to', 1977039)\n",
      "...\n",
      "('dbms_stats', 1)\n",
      "('dbms_output', 1)\n",
      "('dbms_job', 1)\n",
      "Correct!\n",
      "Vocabulary size: 33795\n",
      "Correct!\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "print(\"Total unique tokens :\", len(token_counts))\n",
    "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
    "print('...')\n",
    "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
    "\n",
    "assert token_counts.most_common(1)[0][1] in  range(2500000, 2700000)\n",
    "assert len(token_counts) in range(200000, 210000)\n",
    "print('Correct!')\n",
    "\n",
    "min_count = 10\n",
    "\n",
    "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
    "tokens = [token for token, count in token_counts.items() if count >= min_count]# <YOUR CODE HERE>\n",
    "# Add a special tokens for unknown and empty words\n",
    "UNK, PAD = \"UNK\", \"PAD\"\n",
    "tokens = [UNK, PAD] + sorted(tokens)\n",
    "print(\"Vocabulary size:\", len(tokens))\n",
    "\n",
    "assert type(tokens) == list\n",
    "assert len(tokens) in range(32000, 35000)\n",
    "assert 'me' in tokens\n",
    "assert UNK in tokens\n",
    "print(\"Correct!\")\n",
    "\n",
    "token_to_id = {token: idx for idx, token in enumerate(tokens)}\n",
    "assert isinstance(token_to_id, dict)\n",
    "assert len(token_to_id) == len(tokens)\n",
    "for tok in tokens:\n",
    "    assert tokens[token_to_id[tok]] == tok\n",
    "\n",
    "print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JEsLeBjVycOw"
   },
   "outputs": [],
   "source": [
    "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
    "\n",
    "def as_matrix(sequences, max_len=None):\n",
    "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
    "    if isinstance(sequences[0], str):\n",
    "        sequences = list(map(str.split, sequences))\n",
    "        \n",
    "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
    "    \n",
    "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
    "    for i,seq in enumerate(sequences):\n",
    "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
    "        matrix[i, :len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "id": "JiBlPkdKycOy",
    "outputId": "3866b444-1e2d-4d79-d429-fecc6d8e02a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines:\n",
      "engineering systems analyst\n",
      "hr assistant\n",
      "senior ec & i engineer\n",
      "\n",
      "Matrix:\n",
      "[[10705 29830  2143     1     1]\n",
      " [14875  2817     1     1     1]\n",
      " [27345 10107    15 15069 10702]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Lines:\")\n",
    "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
    "print(\"Matrix:\")\n",
    "print(as_matrix(data[\"Title\"][::100000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "DpOlBp7ZycO6",
    "outputId": "30a911f2-7d35-4cb5-8991-60457b1e8bac"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DictVectorizer</label><div class=\"sk-toggleable__content\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DictVectorizer(dtype=<class 'numpy.float32'>, sparse=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# we only consider top-1k most frequent companies to minimize memory usage\n",
    "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
    "recognized_companies = set(top_companies)\n",
    "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
    "\n",
    "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
    "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yk4jmtAYycO8"
   },
   "source": [
    "### The deep learning part\n",
    "\n",
    "Once we've learned to tokenize the data, let's design a machine learning experiment.\n",
    "\n",
    "As before, we won't focus too much on validation, opting for a simple train-test split.\n",
    "\n",
    "__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes.\n",
    "\n",
    "\n",
    "#### Here comes the simple one-headed network from the seminar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "TngLcWA0ycO_",
    "outputId": "6731b28c-07b1-41dc-9574-f76b01785bba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size =  191814\n",
      "Validation size =  47954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
    "data_train.index = range(len(data_train))\n",
    "data_val.index = range(len(data_val))\n",
    "\n",
    "print(\"Train size = \", len(data_train))\n",
    "print(\"Validation size = \", len(data_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2PXuKgOSycPB"
   },
   "outputs": [],
   "source": [
    "def make_batch(data, max_len=None, word_dropout=0):\n",
    "    \"\"\"\n",
    "    Creates a keras-friendly dict from the batch data.\n",
    "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
    "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
    "    \"\"\"\n",
    "    batch = {}\n",
    "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
    "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
    "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
    "    \n",
    "    if word_dropout != 0:\n",
    "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
    "    \n",
    "    if target_column in data.columns:\n",
    "        batch[target_column] = data[target_column].values\n",
    "    \n",
    "    return batch\n",
    "\n",
    "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
    "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
    "    dropout_mask &= matrix != pad_ix\n",
    "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "colab_type": "code",
    "id": "I6LpEQf0ycPD",
    "outputId": "e3520cae-fba1-46cc-a216-56287b6e4929"
   },
   "outputs": [],
   "source": [
    "a = make_batch(data_train[:3], max_len=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But to start with let's build the simple model using only the part of the data. Let's create the baseline solution using only the description part (so it should definetely fit into the Sequential model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will need these to make it simple\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class Reorder(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.permute((0, 2, 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate minibatches we will use simple pyton generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, **kwargs):\n",
    "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
    "    while True:\n",
    "        indices = np.arange(len(data))\n",
    "        if shuffle:\n",
    "            indices = np.random.permutation(indices)\n",
    "\n",
    "        for start in range(0, len(indices), batch_size):\n",
    "            batch = make_batch(data.iloc[indices[start : start + batch_size]], **kwargs)\n",
    "            target = batch.pop(target_column)\n",
    "            yield batch, target\n",
    "        \n",
    "        if not cycle: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iterate_minibatches(data_train, 3)\n",
    "batch, target = next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is some startup code:\n",
    "n_tokens=len(tokens)\n",
    "n_cat_features=len(categorical_vectorizer.vocabulary_)\n",
    "hid_size=64\n",
    "simple_model = nn.Sequential()\n",
    "\n",
    "simple_model.add_module('emb', nn.Embedding(num_embeddings=n_tokens, embedding_dim=hid_size))\n",
    "simple_model.add_module('reorder', Reorder())\n",
    "simple_model.add_module('conv1', nn.Conv1d(\n",
    "    in_channels=hid_size,\n",
    "    out_channels=hid_size,\n",
    "    kernel_size=2)\n",
    "                       )\n",
    "simple_model.add_module('relu1', nn.ReLU())\n",
    "simple_model.add_module('adapt_avg_pool', nn.AdaptiveAvgPool1d(output_size=1))\n",
    "simple_model.add_module('flatten1', Flatten())\n",
    "simple_model.add_module('linear1', nn.Linear(in_features=hid_size, out_features=1))\n",
    "# <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Title': array([[30160,  7252,     1,     1,     1,     1],\n",
       "        [13520, 12023, 26688, 11346,     1,     1],\n",
       "        [26982, 30069, 11077,   195, 10065, 18192]], dtype=int32),\n",
       " 'FullDescription': array([[30160,  7252, 33403, 33635, 17898, 30762, 12961, 11453, 33331,\n",
       "          2662, 22347, 21405,   965, 13713, 30160,  7261, 30080,   927,\n",
       "         30512, 16289,   965,  5337,  8649, 21721, 33198,  2120, 11295,\n",
       "         22170,  2166, 26033, 29237,   167, 30512, 16289,  2120, 11320,\n",
       "         21721, 30762, 16729,  2120, 11404, 30080, 21405, 24093, 18664,\n",
       "         24027, 30762, 33306,  1297,   965, 32072, 28577, 21405, 15561,\n",
       "           167, 30411, 30160,  7261, 30080,  1567,  2166,  2834,  6361,\n",
       "         21556, 30411, 27479, 31823,   156,  8820,   156, 15353,  2166,\n",
       "          8715, 21405,  6922, 16378, 31089, 24114,   167, 30411, 29406,\n",
       "          5221, 20357, 31639,   965,  6347, 26612,  4938,  2166,  3607,\n",
       "          1048, 30762,  9452,  8619, 16079, 30422,  4938, 16366, 32974,\n",
       "          2401,  6739,  2166, 30131, 11491, 30762,  8704, 24114, 29408,\n",
       "           167,  2810, 33079, 32080,  2166, 33079, 16183, 24253, 11490,\n",
       "          7251,   156, 19332,  2166, 30411, 12552, 21405, 29160,  2166,\n",
       "         23310,   156,  1307,  2662,   965, 31301,  1569, 30762,  6361,\n",
       "           167, 25449, 33079, 26558, 12769, 27345,  4197, 17758, 30578,\n",
       "         30762, 16378,  2166,  4938, 28538,   167, 30411, 26324,   891,\n",
       "         18659, 17437, 26907, 16378, 31089,  8715, 24114, 31639,  6347,\n",
       "         29160,  2166, 25729,   156, 10781, 29406,  8715, 16079, 16378,\n",
       "         28350, 33306, 21604, 33198,  6361, 30762, 24244, 14446, 24569,\n",
       "          1560,  2166,  8707, 29894, 21687, 25864, 12466, 24093, 30080,\n",
       "         18659,  6347, 10692, 31639,  2166,  2395,  3837, 23579, 26188,\n",
       "         18664,  2448, 11068, 28011,   891, 30503, 17758, 10231, 24555,\n",
       "           912, 24093, 18664, 11453, 15402,   965,  6922, 16378, 10866,\n",
       "           912, 29227,  6806,  2166, 16020, 28011,   912, 30985, 25078,\n",
       "         21405, 29406,  8715, 21405, 16378, 24114, 31946, 31022,  2166,\n",
       "         21784,  1695, 19424,   912, 11538,  2166, 11453, 21405,  1894,\n",
       "          2746, 21405, 27079,   912,  1041, 30762, 33306, 33198, 27345,\n",
       "         28828,   156,  6347, 30131, 30103,  2166, 30503, 22390, 29559,\n",
       "           167,  8910, 28011,   891, 23876, 15216, 24558, 17203, 21405,\n",
       "         20166, 12466, 19981, 15652,   156, 23212,  7280, 28980, 15685,\n",
       "          2892, 30411,  9712, 13699, 21556,    80,    80,    80, 24668,\n",
       "         25239, 21196,     0,   115, 21784,  1987,   156, 23212, 10471,\n",
       "         33642,  8167, 30762, 30411, 17958,  1059,   167,     1,     1,\n",
       "             1],\n",
       "        [13520, 12023, 26688, 11346, 14935,    80,  3523,   156,    80,\n",
       "         16873, 21945, 25229,   891,     0,    80, 32718, 20573, 12924,\n",
       "         26688, 29527,   167,  2545, 33635, 21573, 21405, 30426,   927,\n",
       "         32945, 33635,  9526, 32718,  2545, 18235, 12466, 15544, 33198,\n",
       "         24840, 29913,   156, 33010, 33079,  3607,  9802,   156, 30278,\n",
       "          2166, 14009, 33331,   891, 15544, 33010,  5196, 14319, 29894,\n",
       "         30512, 17576, 12154,  2166, 27183,  6835, 30762, 30411, 20752,\n",
       "         17758,   167,  3512, 15402, 30411, 12023,   156, 33635, 33079,\n",
       "         17077, 28886, 33642,  5337, 33198, 12850,  3836, 31046,   156,\n",
       "         10947, 33635, 33198,  1894, 30411, 30842, 33635, 20573, 30762,\n",
       "         21084, 21595, 29394,  4978, 11288, 33209, 33642, 26324,   156,\n",
       "         14569, 30411, 13688, 26563, 12769, 30411, 33299, 13404,   167,\n",
       "         33198, 25864, 12769,  8422, 21573,   156, 33635, 33079,  4828,\n",
       "         33642, 17203, 21405, 30411,  4938, 12769, 30411, 13688, 31823,\n",
       "           156,  5917, 33642, 22123,  7660, 12466, 29402,   167, 20897,\n",
       "         11453, 16289, 20566,   891, 33635,  4625, 30411,  9800,  2166,\n",
       "         33079, 30762, 29394,   912, 32718,   961, 18065, 29894,  5333,\n",
       "         21405, 30411, 25874,   167, 24083, 16289, 24800,  2166,  1321,\n",
       "         10625,   156,  2662, 30411,  4938, 16160, 14276, 15402,  9000,\n",
       "         30762, 10778, 33635, 24887, 33642, 12850, 23500,   156, 13322,\n",
       "         33635, 13597, 25864, 12769, 30411, 22023,   167, 15187, 33635,\n",
       "          2545,  6752,  2882,   156, 10734,   965,  5822,  2166, 30411,\n",
       "         12700, 30762, 27567, 33642, 22123,  5337,   156, 30512, 16289,\n",
       "         30411, 22711, 26324, 12466, 33635,   167, 32945, 33635, 13248,\n",
       "          6886, 26682, 33198, 11295, 21945, 11759, 24083, 21715, 12850,\n",
       "          3836, 31046,  6835,  5303, 19802, 22958, 17432, 22667,  9526,\n",
       "         33635, 14109, 32945, 32718,   961, 24884, 18235, 12466,   927,\n",
       "         10227, 30762,  8664, 17758, 11068, 11295, 32158,  2166, 33438,\n",
       "          6806, 28011,  9800,  2166,  2036, 33198, 30411,  8913, 30762,\n",
       "         29394, 12850,   156, 23678,  6291,   156, 31523,  9813, 17840,\n",
       "          9600,   961, 29840, 19723, 21977,   167,  2395, 21133,   167,\n",
       "         27339, 31909, 33642,  2386, 32230, 30411, 17958, 24668, 25239,\n",
       "             0,    80,   167, 30512, 16658, 32637, 21870, 23459,  2662,\n",
       "         33468,   167, 30895,   167,  6681,   195, 16679,   195,     0,\n",
       "            80],\n",
       "        [ 2120, 11458, 26982, 30069, 16289, 25722, 30762, 33306, 15402,\n",
       "          2120, 11077,   195, 10065, 18192, 26977,   167, 33635, 20357,\n",
       "          3607,   965, 24558, 30069, 21405, 26982,  2166, 14109, 11453,\n",
       "         21405, 30077, 26982, 31823, 30762,  2166, 15447, 17261,    80,\n",
       "         33635, 20357, 14109, 24558, 30069, 28928,   167, 30411, 26977,\n",
       "          2545, 16969, 12466,  5223, 30762,  6700, 15402, 12466,   965,\n",
       "         31209,  8422,  2670, 30762, 19264, 30411, 25874, 21405, 30411,\n",
       "         26982,  8796,  2166, 30762, 13248,   965, 11931, 12466, 30411,\n",
       "         26977, 28242, 16378, 16289, 11068, 33635, 14109,   965,  8090,\n",
       "          7777,  2166, 25242, 21159, 26612, 32817, 30762,  2395,   156,\n",
       "          2662, 18207,  2662, 33635, 14109, 29227,  6279, 18664,  2166,\n",
       "         33094, 30762, 17605, 21556, 30411, 16658, 15187, 33635, 33403,\n",
       "         17898, 30762,  3607,  7197, 12466, 16059, 12466, 30512, 11759,\n",
       "         23445,   156, 10471, 33642,  8167, 30762, 16577,  2670,   167,\n",
       "         16065,  2545, 30762,  3607, 29898, 23128,  2892, 21972,  4552,\n",
       "         21425, 21784, 18192, 21425, 33635, 33079,  3607,  2730, 30762,\n",
       "         24244, 31438, 24024, 25242,  2166, 14109,  2120, 10726,  7777,\n",
       "          5947,  5418, 21977,    32, 15187, 33635,  9526, 21084,  1968,\n",
       "         14632, 21573,    63,  3690,  8820, 15402, 30411, 26977,   167,\n",
       "          8934, 10230, 16289,  2120,  1204, 24569, 18835,  6835,   167,\n",
       "          8934, 10230, 16289,  6782, 30762,   965, 23312, 21405, 10925,\n",
       "         21715,   167, 32718, 25834,  2166, 32033,  8055,  2166, 25492,\n",
       "          9462,  2166, 33079, 21084,  9319, 21556, 30411,  3536, 21405,\n",
       "          1670,   156, 13150,   156, 27521, 21863,   156, 24682,   156,\n",
       "         11130, 21867,   156, 25490,   156,  8057, 21784,  9257,   167,\n",
       "         10010, 15538, 16289,  2792, 21556, 19371,  1958,   167,  9888,\n",
       "         30762, 30411, 14446, 32436, 21405, 25857, 30762, 21972, 23421,\n",
       "         21405, 33306,   156, 21595, 29406,  5223, 33079,  3607,  7282,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1]], dtype=int32),\n",
       " 'Categorical': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remember!__ We are working with regression problem and predicting only one number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1732],\n",
       "        [0.1896],\n",
       "        [0.1708]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try this to check your model. `torch.long` tensors are required for nn.Embedding layers.\n",
    "simple_model(torch.tensor(batch['FullDescription'], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 307)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['FullDescription'].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now simple training pipeline (it's commented because we've already done that in class. No need to do it again)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import clear_output\n",
    "# from random import sample\n",
    "\n",
    "# epochs = 1\n",
    "\n",
    "# model = simple_model\n",
    "# opt = torch.optim.Adam(model.parameters())\n",
    "# loss_func = nn.MSELoss()\n",
    "\n",
    "# history = []\n",
    "# for epoch_num in range(epochs):\n",
    "#     for idx, (batch, target) in enumerate(iterate_minibatches(data_train)):\n",
    "#         # Preprocessing the batch data and target\n",
    "#         batch = torch.tensor(batch['FullDescription'], dtype=torch.long)\n",
    "\n",
    "#         target = torch.tensor(target)\n",
    "\n",
    "\n",
    "#         predictions = model(batch)\n",
    "#         predictions = predictions.view(predictions.size(0))\n",
    "\n",
    "#         loss = loss_func(predictions, target)# <YOUR CODE HERE>\n",
    "\n",
    "#         # train with backprop\n",
    "#         loss.backward()\n",
    "#         opt.step()\n",
    "#         opt.zero_grad()\n",
    "#         # <YOUR CODE HERE>\n",
    "\n",
    "#         history.append(loss.data.numpy())\n",
    "#         if (idx+1)%10==0:\n",
    "#             clear_output(True)\n",
    "#             plt.plot(history,label='loss')\n",
    "#             plt.legend()\n",
    "#             plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual homework starts here\n",
    "__Your ultimate task is to code the three headed network described on the picture below.__ \n",
    "To make it closer to the real world, please store the network code in file `network.py` in this directory. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0eI5h9UMycPF"
   },
   "source": [
    "#### Architecture\n",
    "\n",
    "Our main model consists of three branches:\n",
    "* Title encoder\n",
    "* Description encoder\n",
    "* Categorical features encoder\n",
    "\n",
    "We will then feed all 3 branches into one common network that predicts salary.\n",
    "\n",
    "<img src=\"https://github.com/yandexdataschool/nlp_course/raw/master/resources/w2_conv_arch.png\" width=600px>\n",
    "\n",
    "This clearly doesn't fit into PyTorch __Sequential__ interface. To build such a network, one will have to use [__PyTorch nn.Module API__](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5551/183073953.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'network' from '/home/aznaur/git/ml-course/homeworks_advanced/assignment02_three_headed_network/network.py'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-run this cell if you updated the file with network source code\n",
    "import imp\n",
    "imp.reload(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = network.ThreeInputsNet(\n",
    "    n_tokens=len(tokens),\n",
    "    n_cat_features=len(categorical_vectorizer.vocabulary_),\n",
    "\n",
    "    # this parameter defines the number of the inputs in the layer,\n",
    "    # which stands after the concatenation. In should be found out by you.\n",
    "    concat_number_of_features=6*hid_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_batch, _ = next(iterate_minibatches(data_train, 3))\n",
    "testing_batch = [\n",
    "    torch.tensor(testing_batch['Title'], dtype=torch.long),\n",
    "    torch.tensor(testing_batch['FullDescription'], dtype=torch.long),\n",
    "    torch.tensor(testing_batch['Categorical'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems fine!\n"
     ]
    }
   ],
   "source": [
    "assert model(testing_batch).shape == torch.Size([3, 1])\n",
    "assert model(testing_batch).dtype == torch.float32\n",
    "print('Seems fine!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train the network for a while (100 batches would be fine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training pipeline comes here (almost the same as for the simple_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "lr = 1e-4\n",
    "device = device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "model = network.ThreeInputsNet(\n",
    "    n_tokens=len(tokens),\n",
    "    n_cat_features=len(categorical_vectorizer.vocabulary_),\n",
    "    concat_number_of_features=6*hid_size\n",
    ")\n",
    "opt = torch.optim.Adam(model.parameters(), lr)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "loss_history = []\n",
    "for epoch in range(epochs):\n",
    "    for idx, (batch, target) in enumerate(iterate_minibatches(data_train, batch_size=256)):\n",
    "        batch = [\n",
    "            torch.tensor(batch['Title'], dtype=torch.long).to(device),\n",
    "            torch.tensor(batch['FullDescription'], dtype=torch.long).to(device),\n",
    "            torch.tensor(batch['Categorical']).to(device)\n",
    "        ]\n",
    "        target = torch.tensor(target).to(device)\n",
    "        \n",
    "        preds = model(batch).ravel()\n",
    "        loss = loss_func(preds, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        opt.step()\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        \n",
    "        loss_history.append(loss.item())\n",
    "        \n",
    "        plt.figure(figsize=(14, 8))\n",
    "        plt.grid()\n",
    "        plt.plot(loss_history, label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        clear_output(True)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to evaluate the model it can be switched to `eval` state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThreeInputsNet(\n",
       "  (title_emb): Embedding(33795, 64)\n",
       "  (title_conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,))\n",
       "  (title_act): ReLU()\n",
       "  (title_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (title_out): Flatten(start_dim=1, end_dim=-1)\n",
       "  (full_emb): Embedding(33795, 64)\n",
       "  (full_conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,))\n",
       "  (full_act): ReLU()\n",
       "  (full_out): Flatten(start_dim=1, end_dim=-1)\n",
       "  (category_linear): Linear(in_features=3746, out_features=128, bias=True)\n",
       "  (category_out): ReLU()\n",
       "  (inter_dense): Linear(in_features=384, out_features=128, bias=True)\n",
       "  (final_dense): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(model, data, batch_size=256, name=\"\", three_inputs_mode=True, **kw):\n",
    "    squared_error = abs_error = num_samples = 0.0\n",
    "    output_list = []\n",
    "    for batch_x, batch_y in tqdm(iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw)):\n",
    "        if three_inputs_mode:\n",
    "            batch = [\n",
    "                torch.tensor(batch_x['Title'], dtype=torch.long).to(device),\n",
    "                torch.tensor(batch_x['FullDescription'], dtype=torch.long).to(device),\n",
    "                torch.tensor(batch_x['Categorical']).to(device)\n",
    "            ]\n",
    "        else:\n",
    "            batch = torch.tensor(batch_x['FullDescription'], dtype=torch.long).to(device)\n",
    "\n",
    "        batch_pred = model(batch)[:, 0].detach().numpy()\n",
    "        output_list.append((list(batch_pred), list(batch_y)))\n",
    "        \n",
    "        squared_error += np.sum(np.square(batch_pred - batch_y))\n",
    "        abs_error += np.sum(np.abs(batch_pred - batch_y))\n",
    "        \n",
    "        num_samples += len(batch_y)\n",
    "    print(\"%s results:\" % (name or \"\"))\n",
    "    print(\"Mean square error: %.5f\" % (squared_error / num_samples))\n",
    "    print(\"Mean absolute error: %.5f\" % (abs_error / num_samples))\n",
    "    \n",
    "\n",
    "    batch_pred = [c for x in output_list for c in x[0]]\n",
    "    batch_y = [c for x in output_list for c in x[1]]\n",
    "    output_df = pd.DataFrame(list(zip(batch_pred, batch_y)), columns=['batch_pred', 'batch_y'])\n",
    "    output_df.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:00, 539.01it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (2). Kernel size: (3). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgenerate_submission\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_for_autotest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSubmission\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSubmission file generated\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[34], line 14\u001b[0m, in \u001b[0;36mgenerate_submission\u001b[0;34m(model, data, batch_size, name, three_inputs_mode, **kw)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(batch_x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFullDescription\u001b[39m\u001b[38;5;124m'\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 14\u001b[0m batch_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     15\u001b[0m output_list\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;28mlist\u001b[39m(batch_pred), \u001b[38;5;28mlist\u001b[39m(batch_y)))\n\u001b[1;32m     17\u001b[0m squared_error \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39msquare(batch_pred \u001b[38;5;241m-\u001b[39m batch_y))\n",
      "File \u001b[0;32m~/anaconda3/envs/ptest/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/git/ml-course/homeworks_advanced/assignment02_three_headed_network/network.py:39\u001b[0m, in \u001b[0;36mThreeInputsNet.forward\u001b[0;34m(self, whole_input)\u001b[0m\n\u001b[1;32m     37\u001b[0m input1, input2, input3 \u001b[38;5;241m=\u001b[39m whole_input\n\u001b[1;32m     38\u001b[0m title_beg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtitle_emb(input1)\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 39\u001b[0m title \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtitle_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitle_beg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m title \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtitle_act(title)\n\u001b[1;32m     41\u001b[0m title \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtitle_avg_pool(title)\n",
      "File \u001b[0;32m~/anaconda3/envs/ptest/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/ptest/lib/python3.9/site-packages/torch/nn/modules/conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ptest/lib/python3.9/site-packages/torch/nn/modules/conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    307\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    308\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (2). Kernel size: (3). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "generate_submission(model, data_for_autotest, name='Submission')\n",
    "print('Submission file generated')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Both the notebook and the `.py` file are required to submit this homework.__"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CNN_for_texts.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
